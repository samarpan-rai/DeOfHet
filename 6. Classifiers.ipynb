{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import classification_report\n",
    "import spacy\n",
    "from pure_sklearn.map import convert_estimator\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import balanced_accuracy_score,  make_scorer\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "balanced_accuracy = make_scorer(balanced_accuracy_score, adjusted=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp  = spacy.load('nl_core_news_md') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('./data/processed/woorden_met_hetofde.pickle')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.det.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data = data[['det','woord_vec']]\n",
    "# y_transformed = le.fit_transform(y)\n",
    "\n",
    "train, validation = train_test_split(selected_data, test_size=0.10, stratify=selected_data['det'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.det.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate majority and minority classes\n",
    "df_majority = train[data.det=='de']\n",
    "df_minority = train[data.det=='het']\n",
    " \n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=15588,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "# Display new class counts\n",
    "df_upsampled.det.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_upsampled.woord_vec.tolist()\n",
    "y = df_upsampled.det.tolist()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'n_estimators': 1000}\n",
    "\n",
    "clf_random_forest_untuned = RandomForestClassifier(n_jobs=-1,\n",
    "                                                   n_estimators=2000,\n",
    "                                                   max_depth=5, \n",
    "                                                   class_weight='balanced')\n",
    "clf_random_forest_untuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict in the test set of the upsampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = clf_random_forest_untuned.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict in the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validation = validation['woord_vec'].tolist()\n",
    "y_validation = validation['det'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_on_validation = clf_random_forest_untuned.predict( X_validation )\n",
    "print(classification_report(y_validation, prediction_on_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain with full dataset\n",
    "# clf_random_forest_untuned.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to pure python estimator\n",
    "clf_pure_predict = convert_estimator(clf_random_forest_untuned)\n",
    "with open(\"./data/dumps/random_forest.pickle\",\"wb\") as f:\n",
    "    pickle.dump(clf_pure_predict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf_random_forest = RandomForestClassifier(n_jobs=-1, class_weight='balanced')\n",
    "\n",
    "parameters = {\n",
    "    'n_estimators'      : [10,500,1000],\n",
    "    'max_depth'         : [5, 10, 50, 100],\n",
    "    'max_features': ['auto'],\n",
    "    'criterion' :['gini']\n",
    "}\n",
    "\n",
    "grid_clf_random_forest = GridSearchCV(clf_random_forest, param_grid = parameters,scoring = 'f1', n_jobs=-1)\n",
    "grid_clf_random_forest.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(grid_clf_random_forest.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = grid_clf_random_forest.cv_results_['mean_test_score']\n",
    "stds = grid_clf_random_forest.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, grid_clf_random_forest.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, grid_clf_random_forest.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = grid_clf_random_forest.predict(X_test)\n",
    "np.mean(predicted==y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adaboost with LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_classifier = LogisticRegression(n_jobs=-1,\n",
    "                         penalty='l2',\n",
    "                         C= 0.001, \n",
    "                         random_state=42,\n",
    "                         class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_clf_untuned = AdaBoostClassifier(base_classifier, n_estimators=100, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_clf_untuned.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = adaboost_clf_untuned.predict(X_test)\n",
    "np.mean(predicted==y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(adaboost_clf_untuned, X_train, y_train, cv=3, n_jobs=-1, scoring=balanced_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = clf.predict(X_test)\n",
    "np.mean(predicted==y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_classifier = RandomForestClassifier(n_jobs=-1, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "defualt_adaboost_clf_untuned = AdaBoostClassifier(n_estimators=100, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defualt_adaboost_clf_untuned.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = defualt_adaboost_clf_untuned.predict(X_test)\n",
    "np.mean(predicted==y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defualt_adaboost_clf_untuned_cv_score = cross_val_score(defualt_adaboost_clf_untuned, X, y, cv=3, n_jobs=-1, scoring=balanced_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defualt_adaboost_clf_untuned_cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune on full data set\n",
    "defualt_adaboost_clf_untuned.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to pure python estimator\n",
    "clf_pure_predict = convert_estimator(defualt_adaboost_clf_untuned)\n",
    "with open(\"./data/dumps/adaboost_classifier.pickle\",\"wb\") as f:\n",
    "    pickle.dump(clf_pure_predict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter tuned Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "clf = AdaBoostClassifier(random_state=0)\n",
    "\n",
    "# The list of hyper-parameters we want to optimize. For each one we define the\n",
    "# bounds, the corresponding scikit-learn parameter name, as well as how to\n",
    "# sample values from that dimension (`'log-uniform'` for the learning rate)\n",
    "space  = [\n",
    "          Real(10**-1, 10**1, \"log-uniform\", name='learning_rate'),\n",
    "          Integer(50, 500, name='n_estimators')\n",
    "        ]\n",
    "\n",
    "# this decorator allows your objective function to receive a the parameters as\n",
    "# keyword arguments. This is particularly convenient when you want to set\n",
    "# scikit-learn estimator parameters\n",
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    clf.set_params(**params)\n",
    "\n",
    "    return 1-np.mean(cross_val_score(clf, X, y_transformed, cv=3, n_jobs=-1,\n",
    "                                    scoring=balanced_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import gp_minimize\n",
    "res_gp = gp_minimize(objective, space, n_calls=15, random_state=0,n_jobs=4, verbose=True)\n",
    "\n",
    "\"Best score=%.4f\" % res_gp.fun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = clf.predict(X_test)\n",
    "np.mean(predicted==y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to pure python estimator\n",
    "clf_pure_predict = convert_estimator(clf)\n",
    "with open(\"./data/dumps/GradientBoostingClassifier.pickle\",\"wb\") as f:\n",
    "    pickle.dump(clf_pure_predict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Kass is kaas.\")\n",
    "validation_data = [(token.text, token.vector) for token in doc if token.pos_ == \"NOUN\"]\n",
    "vector_list = [v[1] for v in validation_data]\n",
    "word_list   = [v[0] for v in validation_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pickled model\n",
    "with open(\"./data/dumps/GradientBoostingClassifier.pickle\", \"rb\") as f:\n",
    "    clf = pickle.load(f)\n",
    "    \n",
    "# make prediction with pure-predict object\n",
    "predictions = clf.predict_proba(vector_list)\n",
    "\n",
    "json_result_list = []\n",
    "for prediction, word in zip(predictions,word_list):\n",
    "    json_result = {}\n",
    "    json_result['woord'] = word\n",
    "    json_result['probability'] = {'de' : prediction[0] , 'het' :   prediction[1]}\n",
    "    json_result_list.append(json_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf = GradientBoostingClassifier(random_state=0)\n",
    "\n",
    "n_features=100\n",
    "# The list of hyper-parameters we want to optimize. For each one we define the\n",
    "# bounds, the corresponding scikit-learn parameter name, as well as how to\n",
    "# sample values from that dimension (`'log-uniform'` for the learning rate)\n",
    "space  = [Integer(1, 5, name='max_depth'),\n",
    "          Real(10**-5, 10**0, \"log-uniform\", name='learning_rate'),\n",
    "          Integer(1, n_features, name='max_features'),\n",
    "          Integer(2, 100, name='min_samples_split'),\n",
    "          Integer(1, 100, name='min_samples_leaf')]\n",
    "\n",
    "# this decorator allows your objective function to receive a the parameters as\n",
    "# keyword arguments. This is particularly convenient when you want to set\n",
    "# scikit-learn estimator parameters\n",
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    clf.set_params(**params)\n",
    "\n",
    "    return 1-np.mean(cross_val_score(clf, X, y_transformed, cv=3, n_jobs=-1,\n",
    "                                    scoring=\"f1\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import gp_minimize\n",
    "res_gp = gp_minimize(objective, space, n_calls=50, random_state=0,n_jobs=4, verbose=True)\n",
    "\n",
    "\"Best score=%.4f\" % res_gp.fun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=3,n_jobs=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = neigh.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(predicted==y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "# data_dmatrix = xgb.DMatrix(data=X,label=y_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb = xgb.XGBClassifier(scale_pos_weight=100)\n",
    "# param_dist = {'n_estimators': stats.randint(150, 500),\n",
    "#               'learning_rate': stats.uniform(0.01, 0.07),\n",
    "#               'subsample': stats.uniform(0.3, 0.7),\n",
    "#               'max_depth': [3, 4, 5, 6, 7, 8, 9],\n",
    "#               'colsample_bytree': stats.uniform(0.5, 0.45),\n",
    "#               'min_child_weight': [1, 2, 3]\n",
    "#              }\n",
    "xgb_param = clf_xgb.get_xgb_params()\n",
    "# vresult = xgb.cv(xgb_param, data_dmatrix, nfold=3, metrics=['auc'],stratified=True, maximize = True, seed=1301)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vresult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = [[11, 22, 33, 44],\n",
    "        [55, 66, 77 ,88],\n",
    "        [99, 100, 101, 102]]\n",
    "np.array(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = data.woord_vec\n",
    "y_ = data.det\n",
    "\n",
    "X_train_, X_test_, y_train_, y_test_ = train_test_split(X_, y_, test_size=0.33, stratify=y_ , random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data.woord_vec.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb.set_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selec`tion import RandomizedSearchCV, KFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "clf_xgb = XGBClassifier(objective = 'binary:logistic')\n",
    "param_dist = {'n_estimators': stats.randint(150, 500),\n",
    "              'learning_rate': stats.uniform(0.01, 0.07),\n",
    "              'subsample': stats.uniform(0.3, 0.7),\n",
    "              'max_depth': [3, 4, 5, 6, 7, 8, 9],\n",
    "              'colsample_bytree': stats.uniform(0.5, 0.45),\n",
    "              'min_child_weight': [1, 2, 3]\n",
    "             }\n",
    "clf = RandomizedSearchCV(clf_xgb, param_distributions = param_dist, n_iter = 25, scoring = 'f1', error_score = 0, verbose = 3, n_jobs = -1)\n",
    "\n",
    "numFolds = 5\n",
    "folds = KFold(n_splits = numFolds, shuffle = True)\n",
    "\n",
    "estimators = []\n",
    "results = np.zeros(len(X))\n",
    "score = 0.0\n",
    "for train_index, test_index in folds.split(X):\n",
    "    X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "    y_train, y_test = y.iloc[train_index].values.ravel(), y.iloc[test_index].values.ravel()\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    estimators.append(clf.best_estimator_)\n",
    "    results[test_index] = clf.predict(X_test)\n",
    "    score += f1_score(y_test, results[test_index])\n",
    "score /= numFolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(predicted==y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # convert to pure python estimator\n",
    "# clf_pure_predict = convert_estimator(clf)\n",
    "# with open(\"./data/dumps/random_forest_clf.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(clf_pure_predict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GradientBoostingClassifier.pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_result_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(random_state=1, learning_rate='adaptive',\n",
    "                    max_iter=200).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# convert to pure python estimator\n",
    "clf_pure_predict = convert_estimator(clf)\n",
    "with open(\"./data/dumps/mlp_classifier.pickle\",\"wb\") as f:\n",
    "    pickle.dump(clf_pure_predict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(predicted==y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "clf = linear_model.SGDClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "predicted = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "np.mean(predicted==y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "table = str.maketrans(dict.fromkeys(string.punctuation))  # OR {key: None for key in string.punctuation}\n",
    "text = \"Kass is kass. Dit is kass. Waarom?\"\n",
    "## Strip and lower\n",
    "text = text.strip().lower()\n",
    "## Remove all punctuations\n",
    "text = text.translate(table)  \n",
    "## Only keep uniuqe characters\n",
    "text = ' '.join(set(text.split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join( list(.split())) ) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('datascience': conda)",
   "language": "python",
   "name": "python37464bitdatasciencecondaa6d3a21c00574213ab53e74f2ef82285"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
