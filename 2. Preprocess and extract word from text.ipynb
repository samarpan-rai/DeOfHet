{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import re\n",
    "import plotly.express as px\n",
    "from spacy import displacy\n",
    "from spacy.symbols import NOUN, DET, ADJ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp  = spacy.load('nl_core_news_lg') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('./data/processed/df_wiki_text.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_text_generator(text_list):\n",
    "    \n",
    "    cleanr = re.compile('<.*?>')\n",
    "    for text in text_list:\n",
    "        if isinstance(text, str):\n",
    "            text = text.lower()                 # Converting to lowercase\n",
    "\n",
    "            text = re.sub(cleanr, ' ', text)                 # Removing HTML tags\n",
    "            text = re.sub(r'[?|!|\\'|\"|#]',r'',text)\n",
    "            text = re.sub(r'[.|,|)|(|\\|/]',r' ',text)        # Removing Punctuations\n",
    "\n",
    "            yield text\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_de_of_het(doc):\n",
    "    substantieven = []\n",
    " \n",
    "    for token in doc:\n",
    "\n",
    "    #     print(token.text, token.dep_, token.head.text, token.head.pos_,\n",
    "    #             [child for child in token.children])\n",
    "\n",
    "\n",
    "        if token.pos == NOUN:\n",
    "            # Case 1 : If there is het of de in the POS then extract the head text\n",
    "    #         print(token.text, token.dep_, token.head.text, token.head.pos_,\n",
    "    #             [child for child in token.children])\n",
    "\n",
    "\n",
    "            # Case 2 : There is no clear DET. There must be some ADJ before the noun.\n",
    "\n",
    "            # if the last letter of the adjective is 'e' and  then DET is always de\n",
    "            children = [child for child in token.children]\n",
    "            has_adjective = any([child.pos == ADJ for child in token.children])\n",
    "            has_det = any([child.pos == DET for child in token.children])\n",
    "            has_de_of_het = any([child.lemma_ == 'de' or  child.lemma_ == 'het' for child in token.children])\n",
    "            has_geen_of_een = any([child.lemma_ == 'geen' or  child.lemma_ == 'een' for child in token.children])\n",
    "            if has_adjective or has_det:\n",
    "                found_adj_with_last_letter_e=False\n",
    "\n",
    "                if not has_de_of_het and has_adjective and has_geen_of_een:\n",
    "\n",
    "                    for child in children:\n",
    "                        if child.pos == ADJ:\n",
    "                            if child.text[-1] == 'e':\n",
    "                                substantieven.append(  \n",
    "                                    {'det': 'de',\n",
    "                                     'woord' : token.text,\n",
    "                                     'woord_vec':token.vector\n",
    "                                    } )\n",
    "                                found_adj_with_last_letter_e=True\n",
    "                                break\n",
    "                    if not found_adj_with_last_letter_e:\n",
    "\n",
    "                        substantieven.append( {'det': 'het','woord' : token.text,'woord_vec':token.vector} )\n",
    "#                     print(f\"Token text  {token.text}\")     \n",
    "#                     print(f\"Token children  {children}\")     \n",
    "#                     print(f\"Found adjective ending with 'e' :{found_adj_with_last_letter_e}\" )\n",
    "\n",
    "                if has_de_of_het and not has_geen_of_een :\n",
    "\n",
    "                    for child in children:\n",
    "                        if child.pos == DET:\n",
    "                            substantieven.append( {'det': child.lemma_,'woord' : token.text,'woord_vec':token.vector} )\n",
    "                            break\n",
    "\n",
    "        \n",
    "                \n",
    "    \n",
    "    return substantieven\n",
    "\n",
    "\n",
    "\n",
    "    #         if token.lemma_[-1] == 'e': \n",
    "    #             substantieven.append({'det': 'het','woord' : token.head.lemma_})\n",
    "    #         else : # Else it is a de woord\n",
    "    #             substantieven.append({'det': 'de','woord' : token.head.lemma_})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pipeline : ['tagger', 'parser']\n"
     ]
    }
   ],
   "source": [
    "cleaned_text = pre_process_text_generator(df.text.tolist())\n",
    "\n",
    "substantieven_doc_wise = []\n",
    "with nlp.disable_pipes([\"ner\"]):\n",
    "    docs = nlp.pipe(cleaned_text,n_process=5)\n",
    "    print(f\"Using pipeline : {nlp.pipe_names}\")\n",
    "\n",
    "    for doc in docs:\n",
    "        lidwoordenlijst = extract_de_of_het(doc)\n",
    "        substantieven_doc_wise.append(lidwoordenlijst)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda l: [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3051"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(substantieven_doc_wise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = pd.DataFrame.from_dict(flatten(substantieven_doc_wise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>det</th>\n",
       "      <th>woord</th>\n",
       "      <th>woord_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>de</td>\n",
       "      <td>gemeente</td>\n",
       "      <td>[1.0568, -0.94515, 0.99421, -0.68407, 2.9815, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>de</td>\n",
       "      <td>provincie</td>\n",
       "      <td>[1.716, -1.4213, -0.50323, -2.4624, 1.5628, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>het</td>\n",
       "      <td>dorp</td>\n",
       "      <td>[1.9532, 0.047137, -0.70945, -2.8567, -0.33987...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>het</td>\n",
       "      <td>dorp</td>\n",
       "      <td>[1.9532, 0.047137, -0.70945, -2.8567, -0.33987...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>de</td>\n",
       "      <td>eeuw</td>\n",
       "      <td>[5.555, -2.933, -2.232, -2.0864, 1.9924, 0.687...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   det      woord                                          woord_vec\n",
       "0   de   gemeente  [1.0568, -0.94515, 0.99421, -0.68407, 2.9815, ...\n",
       "1   de  provincie  [1.716, -1.4213, -0.50323, -2.4624, 1.5628, 0....\n",
       "2  het       dorp  [1.9532, 0.047137, -0.70945, -2.8567, -0.33987...\n",
       "3  het       dorp  [1.9532, 0.047137, -0.70945, -2.8567, -0.33987...\n",
       "4   de       eeuw  [5.555, -2.933, -2.232, -2.0864, 1.9924, 0.687..."
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates from name\n",
    "df_processed.drop_duplicates(subset='woord',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.to_pickle('./data/dumps/woorden_met_hetofde.pickle')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('datascience': conda)",
   "language": "python",
   "name": "python37464bitdatasciencecondaa6d3a21c00574213ab53e74f2ef82285"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
